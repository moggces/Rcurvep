---
title: "Test x fraction of chemicals and number of bootstraps"
output: html_notebook
---

## Introduction

The primary dataset has 32 chemicals tested using the same protocol as the other dataset with 80 chemicals. 
The data is dichotomous incidence data and the same bootstrap procedue (n = 1000) was applied. 
For the endpoint *percent_affected_96*, the same baseline noise threshold was identified (25%) using bootstrap number = 1000 and all the chemicals. 

However, it took a lot of time for the above procedue. It will be better to use fewer chemicals and/or fewer number of bootstrap samples to achieve the same outcome. 

## Goal

1. to investigate how the change of the two parameters (**number of bootstrap samples** and **fraction of chemicals**) affects the baseline noise threshold identification. 


## load R packages

```{r, message=FALSE, warning=FALSE}
library(here)
library(Rcurvep)
library(tibble)
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
```


## prepare the dataset

```{r}
zfishdev_boot <- readRDS(here("data-raw", "big_dataset", "biobide32_percent_boot_1000.rds"))
bootd <- zfishdev_boot[["percent_affected_96"]]
#make old format as the new one
bootd <- bootd %>%
  rename(threshold = thres) %>%
  separate(dduid, c("endpoint", "chemical", "direction"), sep = "#") %>%
  separate(direction, c("directionality", "direction"), sep = "@") %>%
  select(-directionality)
  
```


```{r}
sum_act <- extract_curvep_data(bootd, "summary", "INVERSE")
sum_act_hit <- sum_act %>% 
  group_by(chemical, endpoint, direction) %>% 
  summarize(hit_confidence = mean(hit_confidence))

p1 <- ggplot(sum_act_hit, aes(x = hit_confidence)) + geom_histogram()
p1
```


This function is to subset the previously stored bootstrap results and re-calculate the statistics. `Replacement = FALSE`

## functions

```{r}
subset_boot_data <- function(dd, chem_frac, n_sample) {
  sel_sample_ids <- sample(1:1000, n_sample)
  
  chem_names <- dd %>% pull(chemical) %>% unique()
  sel_chem_names <- sample(chem_names, round(length(chem_names)*chem_frac))

  dd_p <- dd %>% 
    filter(chemical %in% sel_chem_names) %>% 
    filter(repeat_id %in% sel_sample_ids)
  result <- extract_curvep_data(dd_p, "act") %>% 
    mutate(POD = ifelse(is.na(POD), conc_highest, POD)) %>%
    identify_basenoise_threshold(., plot = FALSE)
  return(list(thres_d = result, sel_chem = sel_chem_names))
}
```

## Tests
### n_sample = 100 (with all chemicals)

```{r}
set.seed(100)
test_boot_100 <- map(1:20, function(x) {subset_boot_data(dd = bootd, chem_frac = 1, n_sample = 100)})
```

Reducing to n_sample = 100 but with all chemicals can still get the 25% 

```{r}
map(test_boot_100, ~ .x[[1]]) %>% bind_rows() %>% filter(thresDist == 1)
```

```{r}
generate_diagnostic_plot(test_boot_100[[20]][[1]])

```


### n_sample = 10 (with all chemicals)

```{r}
set.seed(10)
test_boot_10 <- map(1:10, function(x) {subset_boot_data(dd = bootd, chem_frac = 1, n_sample = 10)})
```

Reducing to n_sample = 10 but with all chemicals can not get the 25%. The sign that indicates ill-sampling seems to be p2. 


```{r}
map(test_boot_10, ~ .x[[1]]) %>% bind_rows() %>% filter(thresDist == 1)

```

```{r, warning = FALSE, message=FALSE}
generate_diagnostic_plot(test_boot_10[[8]][[1]])
```

### n_sample = 1000 (with 50% of chemicals)

```{r}
set.seed(50)
test_frac_50p <- map(1:10, function(x) {subset_boot_data(dd = bootd, chem_frac = 0.5, n_sample = 1000)})
```

Reducing to 50% of chemicals with n_sample = 1000 can still get the 25% threshold

```{r}
map(test_frac_50p, ~ .x[[1]]) %>% bind_rows() %>% filter(thresDist == 1)

```


### n_sample = 100 (with 50% of chemicals)


```{r}
set.seed(550)
test_frac_50p_boot_100 <- map(1:10, function(x) {subset_boot_data(dd = bootd, chem_frac = 0.5, n_sample = 100)})
```

Reducing to 50% of chemicals with n_sample = 100 cannot guarantee the same threshold


```{r}
map(test_frac_50p_boot_100, ~ .x[[1]]) %>% bind_rows() %>% filter(thresDist == 1)

```

However, there is not much sign to indicate the less optimal threshold is selected

```{r, warning=FALSE, message=FALSE}

generate_diagnostic_plot(test_frac_50p_boot_100[[2]][[1]])

```


### n_sample = 1000 (with 20% of chemicals)

```{r}
set.seed(350)
test_frac_20p <- map(1:10, function(x) {subset_boot_data(dd = bootd, chem_frac = 0.2, n_sample = 1000)})
```

In general, using only 20% of chemicals but keep n_sample = 1000 can still get the 25% threshold.

```{r}
map(test_frac_20p, ~ .x[[1]]) %>% bind_rows() %>% filter(thresDist == 1)

```

```{r}
generate_diagnostic_plot(test_frac_20p[[1]][[1]])

```

```{r}
map(test_frac_20p, function(x) cal_exponential_inflection(x[[1]], xvar = "threshold", yvar = "pooled_variance", p2 = 19))
```



### n_sample = 1000 (with 10% of chemicals)

```{r}
set.seed(560)
test_frac_10p <- map(1:10, function(x) {subset_boot_data(dd = bootd, chem_frac = 0.1, n_sample = 1000)})
```

Surprisingly using only 10% of chemicals can still get the 25% threshold in general. 

```{r}
test_frac_10p %>% bind_rows() %>% filter(thresDist == 1)

```

## Summary

1. It looks like it is better to keep n_sample = 1000 but can reduce the fraction of chemicals to about 20%. However, it could be  
